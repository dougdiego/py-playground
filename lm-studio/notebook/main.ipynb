{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d851be-0eda-48eb-92d3-3c59b31b0159",
   "metadata": {},
   "source": [
    "## Create a Game UI with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ce71f-30ba-4f6a-909c-dc5507284054",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response: I know it's Paris, but could you confirm?\n",
      "\n",
      "Yes, the capital of France is indeed Paris.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the API endpoint and model\n",
    "API_URL = \"http://127.0.0.1:1234/v1/completions\"\n",
    "MODEL_NAME = \"deepseek-r1-distill-qwen-7b\"\n",
    "\n",
    "# Define the request payload\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"prompt\": \"What is the capital of France?\",\n",
    "    \"max_tokens\": 50,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(API_URL, json=payload)\n",
    "\n",
    "# Parse and print the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"Model response:\", result.get(\"choices\", [{}])[0].get(\"text\", \"\").strip())\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebdd6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.17.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (4.7.0)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.1-cp313-abi3-macosx_11_0_arm64.whl.metadata (1.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.7.1 (from gradio)\n",
      "  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub>=0.28.1 (from gradio)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jinja2<4.0 (from gradio)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (24.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pillow<12.0,>=8.0 (from gradio)\n",
      "  Downloading pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (2.10.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.9.7-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec (from gradio-client==1.7.1->gradio)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.7.1->gradio)\n",
      "  Downloading websockets-14.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: certifi in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: requests in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.17.1-py3-none-any.whl (62.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.7.1-py3-none-any.whl (321 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.1-cp313-abi3-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.9.7-py3-none-macosx_11_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading websockets-14.2-cp313-cp313-macosx_11_0_arm64.whl (160 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: markupsafe\n",
      "  Building wheel for markupsafe (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for markupsafe: filename=MarkupSafe-2.1.5-cp313-cp313-macosx_15_0_arm64.whl size=14306 sha256=5da974763d32c0668e75bfd07937d9f9ce798dde4bdb14eadc88dae9ff3c6e53\n",
      "  Stored in directory: /Users/dougdiego/Library/Caches/pip/wheels/c2/0c/c0/d6d953ac80cacc2dd1d329d675c67d1e7775bad02a8faedef0\n",
      "Successfully built markupsafe\n",
      "Installing collected packages: pytz, pydub, websockets, uvicorn, tzdata, tomlkit, shellingham, semantic-version, ruff, python-multipart, pillow, mdurl, markupsafe, fsspec, ffmpy, audioop-lts, aiofiles, starlette, pandas, markdown-it-py, jinja2, huggingface-hub, safehttpx, rich, gradio-client, fastapi, typer, gradio\n",
      "Successfully installed aiofiles-23.2.1 audioop-lts-0.2.1 fastapi-0.115.8 ffmpy-0.5.0 fsspec-2025.2.0 gradio-5.17.1 gradio-client-1.7.1 huggingface-hub-0.29.1 jinja2-3.1.5 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 pandas-2.2.3 pillow-11.1.0 pydub-0.25.1 python-multipart-0.0.20 pytz-2025.1 rich-13.9.4 ruff-0.9.7 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.45.3 tomlkit-0.13.2 typer-0.15.1 tzdata-2025.1 uvicorn-0.34.0 websockets-14.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee95016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages/gradio/chat_interface.py:317: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "demo = None #added to allow restart\n",
    "\n",
    "def start_game(main_loop, share=False):\n",
    "    # added code to support restart\n",
    "    global demo\n",
    "    # If demo is already running, close it first\n",
    "    if demo is not None:\n",
    "        demo.close()\n",
    "\n",
    "    demo = gr.ChatInterface(\n",
    "        main_loop,\n",
    "        chatbot=gr.Chatbot(height=250, placeholder=\"Type 'start game' to begin\"),\n",
    "        textbox=gr.Textbox(placeholder=\"What do you do next?\", container=False, scale=7),\n",
    "        title=\"AI RPG\",\n",
    "        # description=\"Ask Yes Man any question\",\n",
    "        theme=\"soft\",\n",
    "        examples=[\"Look around\", \"Continue the story\"],\n",
    "        cache_examples=False,\n",
    "                           )\n",
    "    demo.launch(share=share, server_name=\"0.0.0.0\")\n",
    "\n",
    "def test_main_loop(message, history):\n",
    "    return 'Entered Action: ' + message\n",
    "\n",
    "start_game(test_main_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bda8570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages/gradio/components/chatbot.py:285: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n",
      "/Users/dougdiego/Developer/github/dougdiego/py-playground/venv/lib/python3.13/site-packages/gradio/chat_interface.py:317: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
      "  warnings.warn(\n",
      "ERROR:    [Errno 48] error while attempting to bind on address ('0.0.0.0', 7860): [errno 48] address already in use\n",
      "ERROR:    [Errno 48] error while attempting to bind on address ('0.0.0.0', 7861): [errno 48] address already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "\n",
    "# Constants\n",
    "API_URL = \"http://127.0.0.1:1234/v1/completions\"\n",
    "MODEL_NAME = \"deepseek-r1-distill-qwen-7b\"\n",
    "demo = None\n",
    "\n",
    "def get_llm_response(prompt):\n",
    "    \"\"\"Get response from local LLM\"\"\"\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 150,  # Increased for longer responses\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result.get(\"choices\", [{}])[0].get(\"text\", \"\").strip()\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error connecting to LLM: {str(e)}\"\n",
    "\n",
    "def chat_with_llm(message, history):\n",
    "    \"\"\"Main chat function that interfaces with the LLM\"\"\"\n",
    "    # Create context from history and current message\n",
    "    context = \"\\n\".join([f\"User: {h[0]}\\nAssistant: {h[1]}\" for h in history])\n",
    "    full_prompt = f\"{context}\\nUser: {message}\\nAssistant:\"\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = get_llm_response(full_prompt)\n",
    "    return response\n",
    "\n",
    "def start_chat(share=False):\n",
    "    global demo\n",
    "    if demo is not None:\n",
    "        demo.close()\n",
    "\n",
    "    demo = gr.ChatInterface(\n",
    "        chat_with_llm,\n",
    "        chatbot=gr.Chatbot(height=600, placeholder=\"Chat with the AI...\"),\n",
    "        textbox=gr.Textbox(placeholder=\"Type your message here...\", container=False, scale=7),\n",
    "        title=\"Chat with Local LLM\",\n",
    "        description=f\"Using model: {MODEL_NAME}\",\n",
    "        theme=\"soft\",\n",
    "        examples=[\"Tell me a short story\", \"What's the weather like today?\", \"Explain quantum computing\"],\n",
    "        cache_examples=False,\n",
    "    )\n",
    "    demo.launch(share=share, server_name=\"0.0.0.0\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
